{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4b3509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:14.299939Z",
     "iopub.status.busy": "2022-10-27T04:34:14.299469Z",
     "iopub.status.idle": "2022-10-27T04:34:16.865764Z",
     "shell.execute_reply": "2022-10-27T04:34:16.864762Z"
    },
    "papermill": {
     "duration": 2.574282,
     "end_time": "2022-10-27T04:34:16.868383",
     "exception": false,
     "start_time": "2022-10-27T04:34:14.294101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from torch.optim import LBFGS\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "torch.manual_seed(1234)            # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(1234)       # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(1234)   # 为所有GPU设置随机种子\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "dtype  = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7e9728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:16.876184Z",
     "iopub.status.busy": "2022-10-27T04:34:16.875375Z",
     "iopub.status.idle": "2022-10-27T04:34:16.886849Z",
     "shell.execute_reply": "2022-10-27T04:34:16.886002Z"
    },
    "papermill": {
     "duration": 0.017339,
     "end_time": "2022-10-27T04:34:16.888928",
     "exception": false,
     "start_time": "2022-10-27T04:34:16.871589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConventBlock(nn.Module):\n",
    "    def __init__(self,in_N,out_N):\n",
    "        super(ConventBlock, self).__init__()\n",
    "        self.Ls  = None\n",
    "        self.net =nn.Sequential(nn.Linear(in_N,out_N),nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self,in_N,m,H_Layer,out_N,**kwargs):\n",
    "        super(Network,self).__init__()\n",
    "        self.xmu  = kwargs[\"xmean\"]\n",
    "        self.xstd = kwargs[\"xstdev\"]\n",
    "        self.tmu  = kwargs[\"tmean\"]\n",
    "        self.tstd = kwargs[\"tstdev\"]\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(ConventBlock(in_N,m))\n",
    "        for i in range(0,H_Layer-1):\n",
    "            layers.append(ConventBlock(m,m))\n",
    "         # output layer\n",
    "        layers.append(nn.Linear(m,out_N))\n",
    "        # total layers\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x,t):\n",
    "        # normalize the input\n",
    "        x = (x - self.xmu)/self.xstd\n",
    "        t = (t - self.tmu)/self.tstd\n",
    "        data = torch.cat((x,t),dim=1);\n",
    "    \n",
    "        out  = self.net(data)\n",
    "        return out \n",
    "    \n",
    "    \n",
    "    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6bb8f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:16.895734Z",
     "iopub.status.busy": "2022-10-27T04:34:16.895173Z",
     "iopub.status.idle": "2022-10-27T04:34:20.882259Z",
     "shell.execute_reply": "2022-10-27T04:34:20.880546Z"
    },
    "papermill": {
     "duration": 3.993007,
     "end_time": "2022-10-27T04:34:20.884617",
     "exception": false,
     "start_time": "2022-10-27T04:34:16.891610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xmean': tensor(0.0043), 'xstdev': tensor(8.6593), 'tmean': tensor(0.5001), 'tstdev': tensor(0.2887)}\n",
      "Network(\n",
      "  (net): Sequential(\n",
      "    (0): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (1): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (2): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (3): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (5): ConventBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (6): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor(0.0043)\n",
      "tensor(8.6593)\n"
     ]
    }
   ],
   "source": [
    "x_lb=-15.0\n",
    "x_rb=15.0\n",
    "t_0 =0\n",
    "t_f=1\n",
    "\n",
    "\n",
    "\n",
    "domain = np.array([[x_lb,t_0],[x_rb,t_f]])\n",
    "x_N = torch.rand(10000000)*(x_rb-x_lb) + x_lb\n",
    "t_N = torch.rand(10000000)*(t_f-t_0) + t_0\n",
    "kwargs ={\"xmean\":x_N.mean(), \"xstdev\":x_N.std(), \"tmean\":t_N.mean(), \"tstdev\":t_N.std()}  \n",
    "print(kwargs)\n",
    "model  = Network(in_N=2,m=100,H_Layer=6,out_N=2,**kwargs)\n",
    "model.to(device)\n",
    "model.apply(init_weights)\n",
    "print(model)\n",
    "print(model.xmu)\n",
    "print(model.xstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1446f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:20.893367Z",
     "iopub.status.busy": "2022-10-27T04:34:20.891822Z",
     "iopub.status.idle": "2022-10-27T04:34:20.897351Z",
     "shell.execute_reply": "2022-10-27T04:34:20.896417Z"
    },
    "papermill": {
     "duration": 0.011903,
     "end_time": "2022-10-27T04:34:20.899603",
     "exception": false,
     "start_time": "2022-10-27T04:34:20.887700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def u_exact(x,t):\n",
    "# #     a = torch.tensor(6**0.5)\n",
    "#     alpha=torch.tensor(-1)\n",
    "#     beta=torch.tensor(-3)\n",
    "#     gamma=torch.tensor(-1.0)\n",
    "#     uo=torch.tensor(-1/5)\n",
    "#     u = uo - alpha / (2 * beta) + (24 * uo * gamma * (4 * uo.pow(2) * beta.pow(2) * t.pow(2) - 2 * uo * beta * x.pow(2) - 3 * gamma)) / ((-4 * uo.pow(2) * beta.pow(2) * t.pow(2) - 2 * uo * beta * x.pow(2) + 3 * gamma).pow(2))\n",
    "#     return u.to(device)\n",
    "\n",
    "\n",
    "# def v_exact(x,t):\n",
    "# #     a = torch.tensor(6**0.5)\n",
    "#     alpha=torch.tensor(-1)\n",
    "#     beta=torch.tensor(-3)\n",
    "#     gamma=torch.tensor(-1.0)\n",
    "#     uo=torch.tensor(-1/5)\n",
    "#     v =-(192 * t * uo.pow(3) * x * beta.pow(2) * gamma) / ((-4 * uo.pow(2) * beta.pow(2) * t.pow(2) - 2 * uo * beta * x.pow(2) + 3 * gamma).pow(2))\n",
    "#     return v.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f500df06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:20.907015Z",
     "iopub.status.busy": "2022-10-27T04:34:20.906146Z",
     "iopub.status.idle": "2022-10-27T04:34:20.918303Z",
     "shell.execute_reply": "2022-10-27T04:34:20.917438Z"
    },
    "papermill": {
     "duration": 0.017938,
     "end_time": "2022-10-27T04:34:20.920342",
     "exception": false,
     "start_time": "2022-10-27T04:34:20.902404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_interior_data(domain,N_data):\n",
    "    \"\"\"\n",
    "    Sampling collocation point:\n",
    "    Args : \n",
    "        - domain :(numpy array) for the size of the domain\n",
    "        - N_data :(int) number of points \n",
    "    out : a tensor of collocation points\n",
    "    \"\"\"\n",
    "    dim = domain.shape[0]\n",
    "    soboleng = torch.quasirandom.SobolEngine(dimension=dim,scramble=True)\n",
    "    data     = soboleng.draw(N_data,dtype=dtype)*(domain[1] - domain[0]) + domain[0]\n",
    "    x       = data[:,0][:,None]\n",
    "    t       = data[:,1][:,None]\n",
    "    return x.to(device),t.to(device)\n",
    "\n",
    "\n",
    "def fetch_initial_data(domain,N_data):\n",
    "    x_min    = domain[0][0]\n",
    "    x_max    = domain[1][0]\n",
    "    soboleng = torch.quasirandom.SobolEngine(dimension=1,scramble=True)\n",
    "    x        = soboleng.draw(N_data,dtype=dtype)*(x_max - x_min) + x_min\n",
    "    t        = (domain[0][1]) *torch.ones_like(x)\n",
    "    return x.to(device),t.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_boundary_data(domain,N_data):\n",
    "    # Left and right BC\n",
    "    N_data   = N_data//2 \n",
    "    \n",
    "    x_min    = domain[0][0]\n",
    "    x_max    = domain[1][0]\n",
    "    \n",
    "    t_min    = domain[0][1]\n",
    "    t_max    = domain[1][1]\n",
    "    \n",
    "    soboleng = torch.quasirandom.SobolEngine(dimension=1,scramble=True)\n",
    "    t        = soboleng.draw(N_data,dtype=dtype)*(t_max - t_min) + t_min\n",
    "#     x_lb     = torch.full_like(t,x_max)\n",
    "#     x_rb     = torch.full_like(t,x_max)\n",
    "    \n",
    "    E_bc     = torch.cat(( torch.full_like(t,x_max),t), dim = 1)\n",
    "    W_bc     = torch.cat(( torch.full_like(t,x_min),t), dim = 1)\n",
    "    \n",
    "    data     = torch.cat((E_bc, W_bc), dim = 0)\n",
    "\n",
    "    \n",
    "    x        = data[:,0][:,None]\n",
    "    t        = data[:,1][:,None]\n",
    "    return x.to(device),t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca94d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:20.927859Z",
     "iopub.status.busy": "2022-10-27T04:34:20.927051Z",
     "iopub.status.idle": "2022-10-27T04:34:20.942189Z",
     "shell.execute_reply": "2022-10-27T04:34:20.941339Z"
    },
    "papermill": {
     "duration": 0.020853,
     "end_time": "2022-10-27T04:34:20.944072",
     "exception": false,
     "start_time": "2022-10-27T04:34:20.923219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def physics_loss(model,x,t):\n",
    "    u,v = model(x,t)[:,0:1], model(x,t)[:,1:2]\n",
    "    u_x,u_t = torch.autograd.grad(u,(x,t), torch.ones_like(u), create_graph=True)\n",
    "    v_x,v_t = torch.autograd.grad(v,(x,t), torch.ones_like(v), create_graph=True)\n",
    "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "    u_xxx = torch.autograd.grad(u_xx, x, torch.ones_like(u_xx), create_graph=True)[0]\n",
    "    u_xxxx = torch.autograd.grad(u_xxx, x, torch.ones_like(u_xxx), create_graph=True)[0]\n",
    "    alpha = torch.tensor(-1)\n",
    "    beta  = torch.tensor(-3)\n",
    "    gamma = torch.tensor(-1.0)\n",
    "    eq_a  = v_t + alpha * u_x + beta * (2 * u * u_x) + gamma * u_xxx\n",
    "    eq_b  = v_x - u_t\n",
    "    loss = eq_a.pow(2) + eq_b.pow(2)\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "def uboundary_loss(model,x,t):\n",
    "    u,v = model(x,t)[:,0:1], model(x,t)[:,1:2]\n",
    "    u_x,u_t = torch.autograd.grad(u,(x,t), torch.ones_like(u), create_graph=True)\n",
    "    loss1   = (u[0:(u.shape[0])//2,:] - u[(u.shape[0])//2:,:]).pow(2)\n",
    "    loss2   = (u_x[0:(u_x.shape[0])//2,:] - u_x[(u_x.shape[0])//2:,:]).pow(2)\n",
    "    loss3   = torch.zeros_like(loss1)\n",
    "    loss4   = torch.zeros_like(loss2)\n",
    "    loss5   = torch.cat([loss1,loss3],0)\n",
    "    loss6   = torch.cat([loss2,loss4],0)\n",
    "    return loss5, loss6\n",
    "    \n",
    "\n",
    "def uinitial_loss(model,x,t):\n",
    "    u,v = model(x,t)[:,0:1], model(x,t)[:,1:2]\n",
    "#     q_x,q_t = torch.autograd.grad(q,(x,t), torch.ones_like(q), create_graph=True)\n",
    "#     r_x,r_t = torch.autograd.grad(r,(x,t), torch.ones_like(r), create_graph=True)\n",
    "    loss  =  (u - torch.exp(-x.pow(2))).pow(2)\n",
    "    return loss\n",
    "\n",
    "def vinitial_loss(model,x,t):\n",
    "    u,v = model(x,t)[:,0:1], model(x,t)[:,1:2]\n",
    "#     q_x,q_t = torch.autograd.grad(q,(x,t), torch.ones_like(q), create_graph=True)\n",
    "#     r_x,r_t = torch.autograd.grad(r,(x,t), torch.ones_like(r), create_graph=True)\n",
    "    loss  =  (v - torch.ones_like(v)).pow(2)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "    \n",
    "def l1_regularization(model, l1_alpha):\n",
    "    regularization_loss = 0\n",
    "    for param in model.parameters():\n",
    "        regularization_loss += torch.sum(abs(param))\n",
    "    return l1_alpha * regularization_loss\n",
    "\n",
    "def l2_regularization(model, l2_alpha):\n",
    "    regularization_loss = 0\n",
    "    for param in model.parameters():\n",
    "        regularization_loss += torch.sum((param)**2)\n",
    "    return l2_alpha * regularization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611ae700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T04:34:20.950989Z",
     "iopub.status.busy": "2022-10-27T04:34:20.950745Z",
     "iopub.status.idle": "2022-10-27T12:55:55.287316Z",
     "shell.execute_reply": "2022-10-27T12:55:55.286129Z"
    },
    "papermill": {
     "duration": 30094.3472,
     "end_time": "2022-10-27T12:55:55.294062",
     "exception": false,
     "start_time": "2022-10-27T04:34:20.946862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========LBFGS Start========\n",
      "epoch : 100, mu: 1000000.0, sum of pde loss: 1.465e+00, penalty loss: 1.159e-09\n",
      "epoch : 200, mu: 1000000.0, sum of pde loss: 1.128e+00, penalty loss: 2.800e-10\n",
      "epoch : 300, mu: 1000000.0, sum of pde loss: 2.828e-01, penalty loss: 1.962e-10\n",
      "epoch : 400, mu: 1000000.0, sum of pde loss: 3.547e-02, penalty loss: 1.040e-11\n",
      "epoch : 500, mu: 1000000.0, sum of pde loss: 1.149e-02, penalty loss: 3.582e-13\n",
      "epoch : 600, mu: 1000000.0, sum of pde loss: 4.932e-03, penalty loss: 5.482e-14\n",
      "epoch : 700, mu: 1000000.0, sum of pde loss: 2.983e-03, penalty loss: 2.461e-14\n",
      "epoch : 800, mu: 1000000.0, sum of pde loss: 1.974e-03, penalty loss: 2.050e-14\n",
      "epoch : 900, mu: 1000000.0, sum of pde loss: 1.498e-03, penalty loss: 1.214e-14\n",
      "epoch : 1000, mu: 1000000.0, sum of pde loss: 1.171e-03, penalty loss: 6.561e-15\n",
      "epoch : 1100, mu: 1000000.0, sum of pde loss: 9.412e-04, penalty loss: 2.922e-15\n",
      "epoch : 1200, mu: 1000000.0, sum of pde loss: 7.878e-04, penalty loss: 1.793e-15\n",
      "epoch : 1300, mu: 1000000.0, sum of pde loss: 6.850e-04, penalty loss: 8.042e-16\n",
      "epoch : 1400, mu: 1000000.0, sum of pde loss: 6.633e-04, penalty loss: 3.590e-16\n",
      "epoch : 1500, mu: 1000000.0, sum of pde loss: 6.203e-04, penalty loss: 3.476e-16\n",
      "epoch : 1600, mu: 1000000.0, sum of pde loss: 6.176e-04, penalty loss: 2.566e-16\n",
      "epoch : 1700, mu: 1000000.0, sum of pde loss: 7.093e-04, penalty loss: 2.284e-16\n",
      "epoch : 1800, mu: 1000000.0, sum of pde loss: 7.099e-04, penalty loss: 1.555e-16\n",
      "epoch : 1900, mu: 1000000.0, sum of pde loss: 7.758e-04, penalty loss: 3.151e-16\n",
      "epoch : 2000, mu: 1000000.0, sum of pde loss: 8.462e-04, penalty loss: 1.239e-16\n",
      "epoch : 2100, mu: 1000000.0, sum of pde loss: 9.481e-04, penalty loss: 2.171e-16\n",
      "epoch : 2200, mu: 1000000.0, sum of pde loss: 9.525e-04, penalty loss: 5.070e-16\n",
      "epoch : 2300, mu: 1000000.0, sum of pde loss: 9.772e-04, penalty loss: 7.330e-16\n",
      "epoch : 2400, mu: 1000000.0, sum of pde loss: 1.005e-03, penalty loss: 5.222e-16\n",
      "epoch : 2500, mu: 1000000.0, sum of pde loss: 9.393e-04, penalty loss: 9.710e-16\n",
      "epoch : 2600, mu: 1000000.0, sum of pde loss: 9.057e-04, penalty loss: 1.151e-15\n",
      "epoch : 2700, mu: 1000000.0, sum of pde loss: 9.016e-04, penalty loss: 9.518e-16\n",
      "epoch : 2800, mu: 1000000.0, sum of pde loss: 9.530e-04, penalty loss: 3.847e-16\n",
      "epoch : 2900, mu: 1000000.0, sum of pde loss: 9.154e-04, penalty loss: 3.220e-16\n",
      "epoch : 3000, mu: 1000000.0, sum of pde loss: 8.478e-04, penalty loss: 2.627e-16\n",
      "epoch : 3100, mu: 1000000.0, sum of pde loss: 8.083e-04, penalty loss: 2.176e-16\n",
      "epoch : 3200, mu: 1000000.0, sum of pde loss: 7.545e-04, penalty loss: 9.247e-17\n",
      "epoch : 3300, mu: 1000000.0, sum of pde loss: 6.670e-04, penalty loss: 2.041e-16\n",
      "epoch : 3400, mu: 1000000.0, sum of pde loss: 5.978e-04, penalty loss: 1.089e-16\n",
      "epoch : 3500, mu: 1000000.0, sum of pde loss: 5.479e-04, penalty loss: 1.692e-16\n",
      "epoch : 3600, mu: 1000000.0, sum of pde loss: 5.085e-04, penalty loss: 2.229e-16\n",
      "epoch : 3700, mu: 1000000.0, sum of pde loss: 4.811e-04, penalty loss: 3.067e-16\n",
      "epoch : 3800, mu: 1000000.0, sum of pde loss: 4.732e-04, penalty loss: 1.816e-16\n",
      "epoch : 3900, mu: 1000000.0, sum of pde loss: 4.540e-04, penalty loss: 5.599e-17\n",
      "epoch : 4000, mu: 1000000.0, sum of pde loss: 4.308e-04, penalty loss: 7.716e-17\n",
      "epoch : 4100, mu: 1000000.0, sum of pde loss: 3.966e-04, penalty loss: 4.677e-17\n",
      "epoch : 4200, mu: 1000000.0, sum of pde loss: 3.718e-04, penalty loss: 3.220e-17\n",
      "epoch : 4300, mu: 1000000.0, sum of pde loss: 3.560e-04, penalty loss: 3.822e-17\n",
      "epoch : 4400, mu: 1000000.0, sum of pde loss: 3.383e-04, penalty loss: 4.273e-17\n",
      "epoch : 4500, mu: 1000000.0, sum of pde loss: 3.316e-04, penalty loss: 2.617e-17\n",
      "epoch : 4600, mu: 1000000.0, sum of pde loss: 3.499e-04, penalty loss: 3.316e-17\n",
      "epoch : 4700, mu: 1000000.0, sum of pde loss: 3.360e-04, penalty loss: 5.495e-17\n",
      "epoch : 4800, mu: 1000000.0, sum of pde loss: 3.269e-04, penalty loss: 1.217e-16\n",
      "epoch : 4900, mu: 1000000.0, sum of pde loss: 3.018e-04, penalty loss: 4.834e-17\n",
      "epoch : 5000, mu: 1000000.0, sum of pde loss: 3.101e-04, penalty loss: 4.125e-17\n",
      "epoch : 5100, mu: 1000000.0, sum of pde loss: 3.217e-04, penalty loss: 3.931e-17\n",
      "epoch : 5200, mu: 1000000.0, sum of pde loss: 3.015e-04, penalty loss: 1.006e-16\n",
      "epoch : 5300, mu: 1000000.0, sum of pde loss: 2.806e-04, penalty loss: 8.533e-17\n",
      "epoch : 5400, mu: 1000000.0, sum of pde loss: 2.865e-04, penalty loss: 3.886e-17\n",
      "epoch : 5500, mu: 1000000.0, sum of pde loss: 2.705e-04, penalty loss: 5.979e-17\n",
      "epoch : 5600, mu: 1000000.0, sum of pde loss: 2.932e-04, penalty loss: 5.913e-17\n",
      "epoch : 5700, mu: 1000000.0, sum of pde loss: 3.196e-04, penalty loss: 7.266e-17\n",
      "epoch : 5800, mu: 1000000.0, sum of pde loss: 3.189e-04, penalty loss: 9.243e-17\n",
      "epoch : 5900, mu: 1000000.0, sum of pde loss: 3.502e-04, penalty loss: 3.527e-17\n",
      "epoch : 6000, mu: 1000000.0, sum of pde loss: 3.332e-04, penalty loss: 2.091e-17\n",
      "epoch : 6100, mu: 1000000.0, sum of pde loss: 3.412e-04, penalty loss: 5.948e-17\n",
      "epoch : 6200, mu: 1000000.0, sum of pde loss: 2.977e-04, penalty loss: 3.712e-17\n",
      "epoch : 6300, mu: 1000000.0, sum of pde loss: 2.430e-04, penalty loss: 1.467e-16\n",
      "epoch : 6400, mu: 1000000.0, sum of pde loss: 2.597e-04, penalty loss: 1.855e-16\n",
      "epoch : 6500, mu: 1000000.0, sum of pde loss: 2.502e-04, penalty loss: 9.066e-17\n",
      "epoch : 6600, mu: 1000000.0, sum of pde loss: 2.986e-04, penalty loss: 5.243e-17\n",
      "epoch : 6700, mu: 1000000.0, sum of pde loss: 2.950e-04, penalty loss: 2.793e-17\n",
      "epoch : 6800, mu: 1000000.0, sum of pde loss: 3.065e-04, penalty loss: 2.219e-17\n",
      "epoch : 6900, mu: 1000000.0, sum of pde loss: 3.033e-04, penalty loss: 4.969e-17\n",
      "epoch : 7000, mu: 1000000.0, sum of pde loss: 2.848e-04, penalty loss: 4.981e-17\n",
      "epoch : 7100, mu: 1000000.0, sum of pde loss: 3.095e-04, penalty loss: 7.180e-17\n",
      "epoch : 7200, mu: 1000000.0, sum of pde loss: 3.301e-04, penalty loss: 8.222e-17\n",
      "epoch : 7300, mu: 1000000.0, sum of pde loss: 4.183e-04, penalty loss: 7.753e-17\n",
      "epoch : 7400, mu: 1000000.0, sum of pde loss: 4.324e-04, penalty loss: 5.286e-16\n",
      "epoch : 7500, mu: 1000000.0, sum of pde loss: 4.647e-04, penalty loss: 4.089e-16\n",
      "epoch : 7600, mu: 1000000.0, sum of pde loss: 5.002e-04, penalty loss: 1.991e-16\n",
      "epoch : 7700, mu: 1000000.0, sum of pde loss: 5.119e-04, penalty loss: 3.518e-17\n",
      "epoch : 7800, mu: 1000000.0, sum of pde loss: 4.895e-04, penalty loss: 1.458e-16\n",
      "epoch : 7900, mu: 1000000.0, sum of pde loss: 4.681e-04, penalty loss: 5.133e-16\n",
      "epoch : 8000, mu: 1000000.0, sum of pde loss: 4.558e-04, penalty loss: 1.697e-16\n",
      "epoch : 8100, mu: 1000000.0, sum of pde loss: 4.257e-04, penalty loss: 2.359e-16\n",
      "epoch : 8200, mu: 1000000.0, sum of pde loss: 3.796e-04, penalty loss: 1.764e-16\n",
      "epoch : 8300, mu: 1000000.0, sum of pde loss: 3.617e-04, penalty loss: 1.506e-16\n",
      "epoch : 8400, mu: 1000000.0, sum of pde loss: 3.672e-04, penalty loss: 4.735e-17\n",
      "epoch : 8500, mu: 1000000.0, sum of pde loss: 4.127e-04, penalty loss: 7.195e-17\n",
      "epoch : 8600, mu: 1000000.0, sum of pde loss: 4.619e-04, penalty loss: 1.692e-16\n",
      "epoch : 8700, mu: 1000000.0, sum of pde loss: 4.508e-04, penalty loss: 2.145e-16\n",
      "epoch : 8800, mu: 1000000.0, sum of pde loss: 4.915e-04, penalty loss: 1.484e-16\n",
      "epoch : 8900, mu: 1000000.0, sum of pde loss: 5.029e-04, penalty loss: 1.575e-16\n",
      "epoch : 9000, mu: 1000000.0, sum of pde loss: 5.425e-04, penalty loss: 2.149e-16\n"
     ]
    }
   ],
   "source": [
    "epochs          = 9000\n",
    "disp            = 100\n",
    "print_to_consol = True\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# update the optimizer\n",
    "optimizer = LBFGS(model.parameters(),\n",
    "                  line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n",
    "                 )\n",
    "\n",
    "\n",
    "# initialize penalty parameter\n",
    "mu           = torch.tensor(1.0)\n",
    "\n",
    "# maximum penalty value for safeguarding\n",
    "mu_max      = torch.tensor(1e6)\n",
    "\n",
    "# l2 norm of constraints |C|_2\n",
    "eta          = torch.tensor(0.0)\n",
    "\n",
    "# penalty tolerance\n",
    "epsilon      = torch.tensor(1e-8)\n",
    "\n",
    "\n",
    "\n",
    "N_data     = 2000\n",
    "\n",
    "# collocation points\n",
    "x_dm,t_dm  = fetch_interior_data(domain,N_data)\n",
    "x_dm       = x_dm.requires_grad_(True)\n",
    "t_dm       = t_dm.requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "N_u        = 200\n",
    "# boundary points \n",
    "x_bc,t_bc  = fetch_boundary_data(domain,N_u)\n",
    "x_bc       = x_bc.requires_grad_(True)\n",
    "t_bc       = t_bc.requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "N_u0       = 100\n",
    "# 1st initial condition points\n",
    "x_ic,t_ic  = fetch_initial_data(domain,N_u0)\n",
    "x_ic       = x_ic.requires_grad_(True)\n",
    "t_ic       = t_ic.requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "# lagrange multiplier for the boundary constraints\n",
    "Lambda_ub1  = torch.zeros_like(x_bc)\n",
    "Lambda_ub2  = torch.zeros_like(x_bc)\n",
    "\n",
    "Lambda_u0 = torch.zeros_like(x_ic)\n",
    "Lambda_v0 = torch.zeros_like(x_ic)\n",
    "\n",
    "\n",
    "\n",
    "print(\"=========LBFGS Start========\")\n",
    "for epoch in range(epochs):\n",
    "    def closure():\n",
    "        if torch.is_grad_enabled():\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        pde_loss     = physics_loss(model,x_dm,t_dm)\n",
    "        \n",
    "        ub_loss1, ub_loss2  = uboundary_loss(model,x_bc,t_bc)\n",
    "\n",
    "        \n",
    "        u0_loss     =  uinitial_loss(model,x_ic,t_ic)\n",
    "        v0_loss     =  vinitial_loss(model,x_ic,t_ic)\n",
    "        \n",
    "        penalty     = (ub_loss1.T@ ub_loss1 + ub_loss2.T@ ub_loss2 + u0_loss.T@ u0_loss + v0_loss.T@ v0_loss).sum()\n",
    "        \n",
    "        \n",
    "        loss        =  pde_loss.sum() +  (Lambda_ub1  * ub_loss1).sum() + (Lambda_ub2 * ub_loss2).sum() + (Lambda_u0 * u0_loss).sum() +  (Lambda_v0 * v0_loss).sum() + 0.5 * mu   * penalty + l1_regularization(model, 1e-5)\n",
    "        \n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def _closure():\n",
    "        model.eval()\n",
    "      \n",
    "        pde_loss     = physics_loss(model,x_dm,t_dm)\n",
    "        \n",
    "        ub_loss1, ub_loss2  = uboundary_loss(model,x_bc,t_bc)\n",
    "\n",
    "        \n",
    "        u0_loss     =  uinitial_loss(model,x_ic,t_ic)\n",
    "        v0_loss     =  vinitial_loss(model,x_ic,t_ic)\n",
    "        \n",
    "        \n",
    "        penalty     = (ub_loss1.T@ ub_loss1 + ub_loss2.T@ ub_loss2 + u0_loss.T@ u0_loss + v0_loss.T@ v0_loss).sum()\n",
    "        \n",
    "        return pde_loss, ub_loss1, ub_loss2, u0_loss, v0_loss, penalty\n",
    "    \n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    pde_loss, ub_loss1, ub_loss2, u0_loss, v0_loss, penalty = _closure() \n",
    "    with torch.no_grad():\n",
    "        if (torch.sqrt(penalty) >= 0.25*eta) and (torch.sqrt(penalty) > epsilon):\n",
    "            mu          = min(mu*2.0, mu_max)\n",
    "            Lambda_ub1  += mu*(ub_loss1)\n",
    "            Lambda_ub2  += mu*(ub_loss2)\n",
    "            Lambda_u0   += mu*(u0_loss)\n",
    "            Lambda_v0   += mu*(v0_loss)\n",
    "            \n",
    "        eta  = torch.sqrt(penalty)\n",
    "        \n",
    "    if (epoch + 1)%disp == 0 and print_to_consol:\n",
    "        print(f'epoch : {epoch+1:3d}, mu: {mu:0.1f}, sum of pde loss: {pde_loss.sum():2.3e}, penalty loss: {penalty.item():2.3e}')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40587b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T12:55:55.310312Z",
     "iopub.status.busy": "2022-10-27T12:55:55.310031Z",
     "iopub.status.idle": "2022-10-27T12:55:55.319487Z",
     "shell.execute_reply": "2022-10-27T12:55:55.318512Z"
    },
    "papermill": {
     "duration": 0.019849,
     "end_time": "2022-10-27T12:55:55.321624",
     "exception": false,
     "start_time": "2022-10-27T12:55:55.301775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model,domain):\n",
    "    model.eval()\n",
    "    x = np.linspace(domain[0][0],domain[1][0],201)\n",
    "    t = np.linspace(domain[0][1],domain[1][1],201)\n",
    "\n",
    "    x_star,t_star = np.meshgrid(x,t)\n",
    "    x_test = torch.tensor(x_star.flatten()[:,None], requires_grad=True).to(device)\n",
    "    t_test = torch.tensor(t_star.flatten()[:,None], requires_grad=True).to(device)\n",
    "\n",
    "    u_pred = model(x_test,t_test)[:,0:1]\n",
    "    u_pred = u_pred.detach().cpu().numpy()\n",
    "    v_pred = model(x_test,t_test)[:,1:2]\n",
    "    v_pred = v_pred.detach().cpu().numpy()\n",
    "#     u_star = u_exact(x_test,t_test)\n",
    "#     u_star = u_star.detach().cpu().numpy()\n",
    "#     v_star = v_exact(x_test,t_test) \n",
    "#     v_star = v_star.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    scipy.io.savemat('X.mat', {'array': x_star.flatten()[:, None]})\n",
    "    scipy.io.savemat('T.mat', {'array': t_star.flatten()[:, None]})\n",
    "    scipy.io.savemat('u_pred.mat', {'array': u_pred.flatten()[:, None]})\n",
    "#    scipy.io.savemat('u_star.mat', {'array': u_star.flatten()[:, None]})\n",
    "    scipy.io.savemat('v_pred.mat', {'array': v_pred.flatten()[:, None]})\n",
    "#    scipy.io.savemat('v_star.mat', {'array': v_star.flatten()[:, None]})\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#     l2_u   = np.linalg.norm(u_star - u_pred, 2)/np.linalg.norm(u_star, 2)\n",
    "#     linf_u = max(abs(u_star - u_pred)).item()\n",
    "    \n",
    "    \n",
    "#     l2_v   = np.linalg.norm(v_star - v_pred, 2)/np.linalg.norm(v_star, 2)\n",
    "#     linf_v = max(abs(v_star - v_pred)).item()\n",
    "    \n",
    "#     return l2_u,l2_v,linf_u,linf_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0aadd42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T12:55:55.338118Z",
     "iopub.status.busy": "2022-10-27T12:55:55.336744Z",
     "iopub.status.idle": "2022-10-27T12:55:55.427803Z",
     "shell.execute_reply": "2022-10-27T12:55:55.426936Z"
    },
    "papermill": {
     "duration": 0.101071,
     "end_time": "2022-10-27T12:55:55.429851",
     "exception": false,
     "start_time": "2022-10-27T12:55:55.328780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpointing the model \n",
    "torch.save(model.state_dict(),f\"gaussofBQ.pt\")\n",
    "# evaluation\n",
    "evaluate(model,domain)\n",
    "# print the l2 norms\n",
    "# print(f\"relative l2_u error :{l2_u:2.3e}, relative l2_v error :{l2_v:2.3e}, linf_u error : {linf_u :2.3e}, linf_v error : {linf_v :2.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30111.142369,
   "end_time": "2022-10-27T12:55:56.800520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-27T04:34:05.658151",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
